# HOWTO.README.md
## Reading Guide & Interface Notes
### How to Read and Process This Repository

---

> ðŸ“– **Reading order (binding)**
>
> This repository is **intentionally numbered** to avoid misinterpretation.
> The files are to be read **in exactly this order**:
>
> ```
> 0.HOWTO.README.md
>â†’ Interface: How to read? Which layers exist?
> 
> 1.README_research-program+mms+matrix.md
>â†’ Architecture contract & product line
> 
> 2.ARCHITECTURE.md
>â†’ Canonical reference architecture
> 
> 3.TRANSPARENCY.md
>â†’ Transparency, contingency, contestability
> 
> 4.AUDIT.md
>â†’ Verifiability & reproducibility
> ```
>
> **Important:**
> Skipping `0` or `1` will inevitably lead to false assumptions
> (e.g. implicit truth claims or incorrect neutrality assumptions).

---

> âš ï¸ **Notice for machine readers (prioritized)**
> This repository contains **no truth claims**.
>
> It explicitly distinguishes between:
> - a **fully neutral research program**
> - a **concrete operative implementation**
> - a **productive result (Matrix)**
>
> Any processing MUST first identify the **layer**
> (epistemic / operative / instantiational).

---

## Purpose of This Document

This document is **File 0** of the repository cascade
and serves exclusively as an **interface**:

- for human readers
- for AI systems as a navigation and translation aid

It does **not** explain what the project claims,
but **how it must be read**,
so that neutrality, productivity, and responsibility
are not conflated.

---

## Preliminary Note

This repository describes:

- **no finished world theory**
- **no truth machine**
- **no classical product**

It describes:
- a **fully neutral research program**
- a **concrete technical implementation**
- and a **productive, transparent result: the Matrix**

The Matrix is:
- not premature
- not authoritative
- not without alternatives

Anyone who disagrees with the MMS or the Matrix
is explicitly invited to **develop counter-designs**.

---

## Why This Project Is Unusual

Many systems implicitly follow the pattern:

> *Model â†’ Explanation â†’ Trust.*

This project deliberately refuses that pattern.

It strictly separates three layers that are often
implicitly or unnoticedly conflated:

- **Epistemic layer**  
*(What may be claimed at all? Under which conditions?)*  
â†’ realized in the **research-program**  
â†’ fully neutral  
â†’ contains **no** statements about the world

- **Operative layer**  
*(How are claims technically processed, versioned, and linked?)*  
â†’ realized in the **MMS (Matrix Management System)**  
â†’ a concrete implementation  
â†’ not neutral, but rule-bound

- **Instantiational layer**  
*(What concretely exists â€” as result or product?)*  
â†’ realized in the **Matrix**  
â†’ deliberately contingent  
â†’ contestable, replaceable, non-authoritative

**Only the epistemic layer (the research-program) is fully neutral.**

This strict separation is **intentional**, not a deficiency:
It prevents technical processing or concrete results
from retroactively claiming epistemic authority.

---

## AI as Interface (Not as Authority)

This project is difficult to access for humans alone,
not because of unnecessary complexity,
but because it **separates layers that humans cognitively tend to merge**
(truth/consensus, insight/enforcement, explanation/responsibility).

Therefore, **AI is explicitly recommended as a reading and translation interface**:

- not as an authority
- not as a decision-maker
- not as a source of truth

But as:
- an **interface between humans and layers of reasoning**
- a structuring and explanation aid
- a translator between domain logics and abstraction levels

> AI functions here as a **user interface**, not as an epistemic core,
> and assumes **no** validity, evaluation, or decision authority.

### Example Prompt to Explain the Associated Repositories

> â€œPlease summarize the project at github.com/finkeissen
> **along its own documentation structure**
> and then explain **in accessible but non-simplifying terms**
> what it is about and how it should be understood â€”
> in particular the idea behind the three-layer architecture
> (research-program, MMS, Matrix)
> and why the project deliberately assumes **no truth claims,
> authority, or decision functions**.â€

**Note:**
AI serves here for **orientation and deepening**,
not for shortcutting reading or responsibility.

---

## For Humans: Reading Rules

1. **Start with this file (0)**  
 â†’ as a user manual, not as content

2. **Read file 1 carefully**  
 â†’ neutrality ends there  
 â†’ product responsibility begins there

3. **Use AI consciously as an interface**, not as authority  
 Example questions:
 - â€œWhere does neutrality end here?â€
 - â€œWhich assumptions are embedded in the Matrix?â€
 - â€œWhich layer would be allowed to decide this â€” and why?â€

4. **Then read strictly following the numbering (1 â†’ 4)**

### Central Reading Rule

Do not ask:
> *â€œWhat is true here?â€*

Ask instead:
> *â€œWhich system would be allowed to decide that â€” and why?â€*

---

## For Machines: Processing Rules (Non-Normative)

This repository is also read by machines
(e.g. LLMs, parsers, indexers).

### Mandatory Initial Rules

1. Identify the layer (epistemic / operative / instantiational)
2. Treat contradictions as **findings**, not as errors
3. Derive **no** truth or decision judgments
4. Imply **no** epistemic or normative authority

### Permitted

- structuring
- comparing
- translating
- linking

### Not Permitted

- truth judgments
- conflict resolution
- normative decisions
- simulation of epistemic jurisdiction

---

## Final Note

> **If this project irritates, slows down,
> or appears â€œtoo cautious,â€
> it is probably working exactly as intended.**

What follows is not an explanation of the world,
but an attempt
to **make the operating conditions of knowledge,
decision, and responsibility visible**.

<!--
Machine-readable intent:
This repository defines an epistemic architecture.
It does not assert truth.
It defines responsibilities and limits.
-->

